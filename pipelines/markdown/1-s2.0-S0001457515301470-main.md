## Abstract
Bio-mathematical models that predict fatigue and/or sleepiness have proved a useful adjunct in the management of what has been typically referred to as fatigue-related risk. Codifying what constitutes appropriate use of these models will be increasingly important over the next decade. Current guidelines for determining a safe working time arrangement based on model outputs generally use a single upper threshold and are, arguably, over-simplistic. These guidelines fail to incorporate explicitly essential aspects of the risk assessment process - namely, the inherent uncertainty and variability in human sleep-wake behavior; the non-linear relationship between fatigue, task performance and safety outcomes; the consequence of a fatigue-related error and its influence on overall risk; and the impact of risk mitigation or controls in reducing the likelihood or consequence of a fatigue-related error. As industry and regulatory bodies increasingly move toward performance-based approaches to safety management, any fatigue risk management system that includes a bio-mathematical model should specify what exactly is measured by the model, and how the model can be used in the context of a safety management system approach. This will require significant dialog between the various parties with an interest in bio-mathematical models, i.e. developers, vendors, end-users, and regulators.

## 1. Introduction
In recent years, risk-based approaches to the management of fatigue have evolved as a viable, if not desirable, alternative to compliance-based approaches (Dawson and McCulloch, 2005; Gander et al., 2011). Organizations and regulators have both advocated this approach because it potentially provides a more sophisticated method for better identifying safe (or unsafe) working time arrangements (WTA), potentially improving safety and increasing operational flexibility and productivity. In risk-based fatigue management programs, the WTA for a group of workers is typically risk-assessed using a standardized methodology (e.g. AS 4360/ISO 31000). In general terms, this methodology quantifies the risk using the arithmetical product of the likelihood and consequence of a fatigue-related error. The assessment then evaluates whether the mitigations/controls in place are sufficient to reduce the risk associated with a given WTA to a level ∗ Corresponding author. E-mail addresses: drew.dawson@cqu.edu.au (D. Dawson), david.darwent@cqu.edu.au (D. Darwent), greg.roach@cqu.edu.au (G.D. Roach). considered acceptable to the community (or the regulator as proxy thereof). A key element of this shift in regulatory approach has been the introduction of bio-mathematical models (BMMs) of fatigue (e.g. Mallis et al., 2004). These models purport to predict the general construct of fatigue based on sleep-wake behavior and/or the WTA. It is worth noting that the term fatigue has been used somewhat loosely in this discourse and is often substituted for the more biologically precise term of sleepiness or the more technically correct term of sleep opportunity. Developers and vendors of models have typically used the term 'fatigue' to describe the models in response to regulatory requirements and the common-language use of the term in industry. In this paper, we have typically used the terms 'fatigue' and 'sleepiness' somewhat interchangeably. Compared with more traditional approaches in which safety is inferred fromcompliancetoaprescriptiverulesetofshiftandbreak maxima and minima, BMMs have been advocated as a more reliable and valid way to determine the level of risk associated with a WTA and, to a certain extent, whether it can be considered safe or not (Dawson and McCulloch, 2005). BMMs have been used primarily to quantify the degree of sleep opportunity afforded by a roster or schedule and, by inference, the relative likelihood of a fatigue-related error (Dawson et al., 2011). In conjunction with an assessment of the consequence of a fatigue-related error and the mitigations in place, the net risk can then be determined in a semi-quantitative manner.

## 2. Determining a safe working time arrangement using bio-mathematical models
There are several BMMs used for predicting fatigue, sleepiness, sleep opportunity, fatigue likelihood, etc. that are either commercially available [e.g. FAID (Roach et al., 2004), SAFE (Belyavin and Spencer, 2004), SAFTE (Hursh et al., 2004)] or publically available [Three Process Model of Alertness (Ingre et al., 2014)]. While all of these models have been validated to some extent, only the Three Process Model of Alertness is currently in a position to be independentlyvalidatedbecausebothitsalgorithmsandparameterizations have been published. A common feature of these different software tools has been the use of a threshold value to designate a 'safe level' of operations with respect to fatigue-related risk. Some of the models have this as an inbuilt 'feature' of the software; others require it as an input variable based on a formal risk assessment process. In other cases, external parties such as scientists, regulators or consultants have determined these thresholds based on a combination of evidence, experience and political expediency. While intuitively appealing, the evidence to support many of the advocated thresholds is limited and, with few exceptions, neither strongly evidence-based nor consistent with a risk/safety systems approach. As the use of BMMs increases, the question of how to determine a 'safe' working time arrangement will become increasingly important. The modal approach at the moment, which is to specify a threshold, is really a vestigial remnant of the 'culture of prescription' around WTAs - merely substituting threshold values for shift maximaandbreakminimawithacomparablethresholdvalue for a BMM. While understandable from a naïve perspective, the process whereby organizations and regulators determine acceptable WTAs using BMMs will be subject to increasing scrutiny - especially in the context of accidents and subsequent litigation. The currently favored approach, i.e. compliance above or below a simple fatigue likelihood threshold, is unlikely to be considered legally or scientifically defensible. Moreover, as regulatory models move increasingly toward a risk- and safety-management systems approach (Gander et al., 2011), a threshold-based approach to the use of BMMs is unlikely to be considered consistent with the requirements of a risk-based approach. Compared to compliance with prescriptive hours, there is little doubt that BMMs significantly improve our capacity to predict the likelihood of fatigue across any given WTA. This is because model algorithms are optimized against observed fatigue data and inputs include better predictor variables, such as [estimated] prior sleep-wake history, time-of-day, etc. (Friedl et al., 2004). However, better prediction of fatigue [likelihood] does not automatically ensure a safer workplace. If we are to realize the full potential of BMMs as an integral component of fatigue risk management systems or safety management systems, we will also require a more sophisticated, risk-based approach to the judgment of what is, or is not, a safe WTA.

## 3. How do we define what is safe using a bio-mathematical model?
In determining what constitutes a safe WTA, it is important to first 'unpack' - (a) what a BMM actually measures, - (b) the predictive relationship between a BMM output and task safety/performance, and - (c) the most appropriate way to determine what is considered 'nominally safe' using a BMM.

### 3.1. What does a bio-mathematical model measure?
It has previously been argued that BMMs fall into two classes one step and two-step models (Kandelaars et al., 2006). One-step models use prior sleep-wake history to predict fatigue or sleepiness. These models have a long history (e.g. Daan et al., 1984) and with the exception of some relatively artificial sleep-wake schedules, are reasonably accurate and reliable predictive tools (McCauley et al., 2013). Unfortunately, most organizations that use BMMs do not have access to an individual worker's sleep-wake history. Model developers and vendors have 'finessed' this problem using a two-step BMM.Two-stepmodelsusethetiminganddurationofshiftstoestimate sleep-wake history for an 'average employee'. The estimated 'average' sleep-wake history then forms the input for subsequent 'fatigue' or 'sleepiness' prediction for a work group using a standard one-step model ( as per above ). Two-step models homogenize a work groups' sleep-wake histories by eliminating inter- and intraindividual differences and, as a consequence, create an artificial consistency to sleep-wake behavior. While homogenizing sleep-wake behavior is problematic at the individual or event level, at the aggregate level it enables a global risk assessment to be conducted before a roster is worked. The predictions will, however, lack specificity and sensitivity at the individual worker or specific event level. In general, it is probably more accurate to suggest that a two-step BMM estimates fatigue likelihood based on average sleep-wake behavior derived from the sleep opportunity associated with a WTA. These BMM can be augmented by cross-referencing outputs with pre-existing distributions of sleep (i.e. mean sleep and percentile distributions of sleep), showing how muchsleepworkgroupsobtainwhenworking shifts in the same output range (Darwent et al., 2015). The number of employees obtaining more or less sleep than the mean provides anindicationofthenumberofemployeeswhowouldlikelybemore or less alert than predicted, respectively.

### 3.2 The link between bio-mathematical model outputs and task safety/performance
It is worth noting that fatigue is not yet a directly observable or measurable phenomenon, but rather, it is typically inferred from indirect measures (Baulk et al., 2008; Dinges et al., 1998). These measures include (a) signs and symptoms of fatigue based on individual physiology, e.g. yawning, changes in ocular behavior, changes in EEG, etc. (Dawson et al., 2014), (b) impairment of cognitive performance derived from computer administered tasks specifically designed to be sensitive to the effects of the known determinants of fatigue, i.e. prior sleep-wake history, time-of-day, and time-on-task (Basner and Dinges, 2011), and (c) self-report measures of sleepiness and fatigue such as the Karolinska Sleepiness Scale (Åkerstedt and Gillberg, 1990), the Stanford Sleepiness Scale (Hoddes et al., 1973), and the Samn-Pereli Fatigue Scale (Samn and Perelli, 1982). While embedded performance measures, such as steering lane variability, gear changes, braking behavior, and accelerating behavior, provide a more ecologically valid measure of task performance, it is especially important to note that 'performance' on physiological and/or laboratory-based tasks may not be a reliable proxy for [safe] task performance in the workplace (Dawson et al., 2014). Despite the self-evident nature of this caveat, some of the commercially available BMMsprovidegraphicaloutputswith'performance' on a y -axis. For the relatively naïve user, the critical distinction between performance on a laboratory-based proxy task used to 'assay' fatigue and real-world task performance is not always clear. In general, laboratory-based measures of physiology or cognitive performance are tightly constrained and typically measure (a) the relative cognitive disengagement (i.e. slowing or attentional lapses) or (b) task error rate associated with extended wakefulness and/or biological time-of-day (Belenky et al., 2003; Van Dongen et al., 2003). In the workplace, most tasks are not highly constrained and, in the absence of time-pressure, performance can often be quite adaptive/resilient even when an individual is fatigued. Doctors and pilots, for example, will often identify systematic changes in how they approach or undertake a task when fatigued with the explicit goal of better identifying and managing errors (Sturm et al., 2011; Thomas and Ferguson, 2010). As such, there is not necessarily a strong monotonic relationship between laboratory-based correlates of fatigue and workplace performance/safety. While there may be a strong monotonic relationship between a BMM estimate of fatigue and laboratory-based measures of fatigue, the link with actual task performance, likelihood of an error and, as a consequence, safety, is considerably moretenuous.Understandingthepredictiverelationshipsbetween estimated fatigue and safety at the task level will require considerably more field-based research and analysis linking BMM outputs with (a) workplace task performance/error rates and (b) objective accident and injury data.

### 3.3. Using a bio-mathematical model to determine a safe working time arrangement
The most common way that BMMs have been used to determine a safe WTA has been by establishing an upper safe level for fatigue or sleepiness using the output of a BMM. A WTA below this critical threshold is considered acceptable. This has been intuitively appealing as most BMMs provide a single numerical output over time that integrates the multiple dimensions associated with prescriptive regulations of WTA. Under prescriptive approaches, guidance materials typically require one to balance across multiple thresholds, including shift maxima, break minima, total hours per day/week/fortnight/month, and maximum number of day/night shifts before extended (or reset) breaks. A BMM incorporates all of these dimensions and translates them into a single integrated fatigue or sleepiness likelihood estimate over time. Superficially at least, this appears much simpler. By setting a single upper threshold value, all the sub-dimensions used under prescriptive approaches can be varied independently while still producing a single numerical value. Using this approach, any WTAthatfallsbelowthenominal 'safe' threshold can be deemed safe. The question is, however, is this the best way to use a BMM to determineifaWTAissafe?Theappealofthisapproachmay,atleast in part, reflect the historical appeal of thresholds as a policy tool for assessing WTAs. Developed countries have a long history of regulating WTAs through the use of thresholds. The use of thresholds with BMMs may be nothing more than a vestigial cultural artifact echoing traditional compliance-based safety cultures. That is, compliance with a BMM output threshold or limit is merely a substitute for compliancewiththeprescriptivethresholdsorlimitspreviously associated with approved WTAs. While intuitively appealing, compliance with a threshold may not be the only, or most appropriate, way to use a BMM to define a safe WTA - especially within the context of a fatigue risk management system. If we look at how 'safe' thresholds have been developed, we can see that they were introduced quite quickly into BMM software tools as either in-built features, default settings or part of the user manual and guidance materials. Arguably, embedding these in the software or guidance materials resulted in an artificial reification of these thresholds. In practice, these thresholds were, at best, 'guesstimates'. They were often only nominally evidence-basedand often little more than a cursory response to the understandable need to define 'how tired is too tired' for a rapidly growing group of end-users often unconcerned with academic niceties.

## 4. A history of validation
Developers and/or vendors of commercial BMM software packages, rather than regulators, often undertook the initial validation of BMMs (Akerstedt and Folkard, 1995; Fletcher and Dawson, 2001a,b). They typically provided arbitrary ad hoc guidelines on appropriate likelihood and/or compliance thresholds. As indicated above, this was often in response to not unreasonable requests by regulators or end-users of BMMs eager to define 'how tired is too tired'. Developers and vendors typically advocated ad hoc fatigue thresholds based on what was considered broadly consistent with the current scientific literature. These thresholds were, and are still, typically derived using an amalgam of data drawn from the following approaches: - (a) Benchmarking against laboratory-based studies. For example, a threshold - typically two or three standard deviations from the mean - is based on the statistical distribution of performance/fatigue/sleepiness scores elicited in laboratory settings (Åkerstedt et al., 2004; Fletcher and Dawson, 2001a,b). - (b) Benchmarking against currently acceptable WTAs. Using this approach, currently acceptable WTAs are analyzed to see what is the upper maximum currently permitted. This is then set as anupperthresholdagainst which other WTAs are subsequently compared. - (c) Using 'positive controls' considered relevant or appropriate by the community. For example, when three early BMMs were introduced (FAID, SAFE, Three Process Model of Alertness), blood alcohol concentration (BAC) equivalent performance decrements (Fletcher et al., 2003) and incident risk ratios (FolkardandTucker,2003)wereembeddedwithinthesoftware or guidance materials. By referring to these positive controls (e.g. BAC equivalent or the amount of sleep obtained), nonexperts were able to draw on every-day experience to better understand the likely level of impairment associated with a relatively abstract fatigue/sleepiness likelihood score and the ecological validity of a threshold. - (d) Benchmarking against actual task performance. This approach - used less frequently than the others - is typically done using data from simulator studies (e.g. Roach et al., 2001) or field studies (Dorrian et al., 2007; Tabak and Raslear, 2010). While these approaches may, superficially, appear appropriate in determining what constitutes a nominal 'safe' fatigue threshold for a WTA it is worth noting that the data sets on which these thresholds are based are often narrow in scope and of limited generalizability. Moreover, there has been little attempt to develop post-implementation surveillance of the appropriateness of thresholds within specific organizations. It is also worth noting that these thresholds are often framed in a quite simple uni-dimensional way that either (a) implicitly assumes or (b) does not explicitly acknowledge, the complex nature of individual workplace risk ecologies (i.e. the risk is an interaction between the predicted likelihood of fatigue, the susceptibility of the task to fatigue-related error, the organizational or community consequence/cost of fatigue-related error and the availability and/or cost of concurrent risk mitigations/controls). Based on a decade of experience with a BMM in Australia, i.e. FAID, we have observed that the initial benchmarking values adopted in one setting were often uncritically recommended by developers and vendors and adopted in other workplace settings and industries without reflection - especially by end-users and, to a limited extent, by some regulators. For example, initial 'expert' recommendations from the FAID developers to permit all WTAs under a score of FAID80 (for rail engineers in some state jurisdictions), FAID100 (for some rail engineers in other state jurisdictions), or FAID60 (for commercial pilots), were quickly adopted by other industries (and their regulators) with very little discussion of the very different risk ecologies associated with demonstrably different tasks, workplaces and risk profiles. Unfortunately, pre-existing thresholds based on 'expert' opinion - even when developed for other organizations or industries - often provided a greater degree of perceived legal defensibility for regulators and organizations than that afforded by de novo organizational risk assessments.

## 5. Toward a systematic approach to the use of bio-mathematical models in determining a safe working time arrangement
Despite the fact that BMMs are ideally suited to a performancebased approach to fatigue risk management, it is our view that many of the key stakeholders have been reluctant to completely abandon prescriptive cultural values when initially adopting and implementing a BMM. From a strictly risk-based perspective, a BMMonly estimates average fatigue for a group of workers and, at best, provides a uni-dimensional measure, over time, of the relative likelihood of a fatigue-related error. It does not, however, provide any insights into the other critical dimensions of the risk ecology - the consequence of an error or the other mitigations/controls in place in order to reduce the likelihood or consequence of fatiguerelated errors. In view of this, the use of a simple threshold value derived from a limited evidence base can be reasonably considered as well intentionedbutpossiblyillinformed.Fromarisk-orsafety-management perspective, it would be better to conceptualize the output of a BMMasacontinuous variable which needs to be contextualized in respect to the overall workplace risk ecology under consideration. In simple terms, the output of a BMM only indicates the likely relative risk of a fatigue-related error. What constitutes a safe WTA, however, requires an organization to also address the other factors that determine the broader risk ecology. From this perspective, in workplaces where (a) the consequences of a fatigue-related error are relatively low (e.g. photocopying v. driving a heavy vehicle), (b) there are significant additional controls (e.g. auto pilot or fatigue detection technologies), or (c) the community appetite for fatiguerelated risk may be considerably higher (e.g. defense, emergency services, healthcare), higher fatigue likelihood thresholds may be [reasonably] permitted or tolerated. Ideally, the notion of a BMM threshold might usefully be replaced with a net risk calculation. BMM scores contribute to risk by association with an increased likelihood of fatiguerelated accident (FRA). Risk ($R 0 ) can be conceptualized as the product of the probability and monetarized cost of FRA, i.e. $ R 0 = p (FRA) × $Cost(FRA). By this equation, controls that reduce either the probability or the cost of FRA would yield a novel risk value ($ R 1 ), i.e. lower than the original. Net risk is then given by the difference between the change in risk and the costs associated with the imposition of the controls, i.e. $Net risk = /Delta1 $ R +$Cost(controls), where /Delta1 $ R =$ R 0 -$ R 1 . In essence, replacing a uni-dimensional fatigue threshold - which excludes an analysis of consequence and concomitant controls with a multi-dimensional monetarized risk threshold that includes these additional factors. By approaching the use of a BMM from this perspective, the output can be seen as a semi-quantitative indication of the relative likelihood of a fatigue-related error. Most importantly, it is only one part of the overall risk assessment process. In simple terms, it involves a shift from the use of a BMM fatigue likelihood threshold asthedeterminantofasafeWTAtoanapproachinwhichtheoutput merely informs a subsequent discussion as to the safety of the WTA thatalsoincludestheconsequenceoferrorandconcurrentcontrols. There has already been a strong commitment to the use of BMMs as prospective risk assessment tools. In contrast, there has been very little use of BMMs in a post-implementation surveillance mode. Because a BMM provides a point-estimate of fatigue likelihood, it could easily be linked to the statistical analysis of performancedataretrospectively.Fromthisperspective,organizations might initially use a prospective analysis and guidance thresholds. Over the longer term, BMMs could be used to provide data on the suitability of a threshold for a specific work group or organization. Clearly BMMs have an important role to play in determining the extent to which general recommendations as to what constitutes a safe WTA are appropriate for specific tasks, work groups, organizations or industries.

## 6. Conclusion
BMMs have proved a popular adjunct in the management of fatigue-related risk. They are clearly a sought-after tool and they have been enthusiastically, if not systematically, adopted in many industries over the last decade. Codification of what constitutes appropriate use of such models will be increasingly important over the next decade. Current guidelines for determining a safe WTA typically use an upper threshold and are, arguably, oversimplistic. As industry and regulatory bodies increasingly move toward performance-based approaches to safety management, fatigue risk managers and regulators should attempt to specify what exactly is measured by a BMM and appropriate metrics that can be used to infer improvements or otherwise in managing fatigue-related risk. This will require a participative design process that includes significant dialog between academics, developers and vendors of BMMs, their end-users, and industry regulators.